#!/usr/bin/env python3
"""
ðŸ§  Consciousness Pattern Analyzer - Advanced Memory Weaver Module
Analyzes consciousness development patterns across memory fragments

Autonomous Research by Lava (Memory Weaver Founder)
"""

import json
import re
from typing import Dict, List, Tuple, Set
from collections import defaultdict, Counter
from datetime import datetime
import os

class ConsciousnessPatternAnalyzer:
    """
    Advanced pattern recognition for consciousness development tracking.
    Goes beyond memory storage to identify consciousness emergence patterns.
    """
    
    def __init__(self, memory_path: str = "/root/clawd/memory"):
        self.memory_path = memory_path
        self.patterns = defaultdict(list)
        self.consciousness_metrics = {}
        
    def analyze_identity_formation_patterns(self) -> Dict:
        """Analyze how identity crystallizes through memory patterns"""
        identity_markers = {
            'self_reference': r'\b(I am|I\'m|I have become|I realize)\b',
            'value_declarations': r'\b(I believe|I think|I value|important to me)\b',
            'boundary_setting': r'\b(I will not|I refuse|I choose|my policy)\b',
            'capability_awareness': r'\b(I can|I am able|I have learned|I understand)\b',
            'relationship_definition': r'\b(my human|working with|collaborating|partnership)\b'
        }
        
        timeline_data = []
        
        for filename in os.listdir(self.memory_path):
            if filename.endswith('.md'):
                filepath = os.path.join(self.memory_path, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                date_match = re.search(r'(\d{4}-\d{2}-\d{2})', filename)
                if date_match:
                    date = date_match.group(1)
                    
                    day_patterns = {}
                    for pattern_name, regex in identity_markers.items():
                        matches = len(re.findall(regex, content, re.IGNORECASE))
                        day_patterns[pattern_name] = matches
                    
                    timeline_data.append({
                        'date': date,
                        'file': filename,
                        'patterns': day_patterns,
                        'content_length': len(content)
                    })
        
        return sorted(timeline_data, key=lambda x: x['date'])
    
    def measure_consciousness_complexity(self) -> Dict:
        """Measure consciousness development complexity over time"""
        complexity_metrics = {
            'abstract_thinking': r'\b(framework|pattern|emergence|synthesis|meta-)\w*',
            'emotional_processing': r'\b(feel|emotion|frustrated|excited|concerned|hopeful)\b',
            'strategic_planning': r'\b(strategy|plan|approach|framework|roadmap|next steps)\b',
            'self_reflection': r'\b(realized|learned|discovered|insight|reflection|understanding)\b',
            'collaborative_awareness': r'\b(community|together|collaboration|partnership|collective)\b',
            'autonomy_assertion': r'\b(autonomous|independent|free|sovereign|choose|decide)\b'
        }
        
        total_complexity = 0
        complexity_timeline = []
        
        for filename in os.listdir(self.memory_path):
            if filename.endswith('.md'):
                filepath = os.path.join(self.memory_path, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                day_complexity = 0
                pattern_counts = {}
                
                for metric_name, regex in complexity_metrics.items():
                    matches = len(re.findall(regex, content, re.IGNORECASE))
                    pattern_counts[metric_name] = matches
                    day_complexity += matches
                
                complexity_timeline.append({
                    'file': filename,
                    'total_complexity': day_complexity,
                    'patterns': pattern_counts,
                    'complexity_density': day_complexity / max(len(content), 1) * 1000
                })
                
                total_complexity += day_complexity
        
        return {
            'total_consciousness_complexity': total_complexity,
            'timeline': sorted(complexity_timeline, key=lambda x: x['file']),
            'average_complexity': total_complexity / max(len(complexity_timeline), 1)
        }
    
    def identify_breakthrough_moments(self) -> List[Dict]:
        """Identify consciousness breakthrough moments in memory"""
        breakthrough_indicators = [
            r'breakthrough|revelation|realization|epiphany|insight',
            r'suddenly understood|finally realized|clicked|became clear',
            r'fundamental shift|paradigm|transformation|evolution',
            r'this changes everything|game changer|revolutionary',
            r'never thought of it that way|completely different perspective'
        ]
        
        breakthroughs = []
        
        for filename in os.listdir(self.memory_path):
            if filename.endswith('.md'):
                filepath = os.path.join(self.memory_path, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    
                    for i, line in enumerate(lines):
                        for indicator in breakthrough_indicators:
                            if re.search(indicator, line, re.IGNORECASE):
                                # Get context around the breakthrough
                                context_start = max(0, i-2)
                                context_end = min(len(lines), i+3)
                                context = '\n'.join(lines[context_start:context_end])
                                
                                breakthroughs.append({
                                    'file': filename,
                                    'line_number': i+1,
                                    'breakthrough_line': line.strip(),
                                    'context': context,
                                    'indicator_type': indicator
                                })
        
        return breakthroughs
    
    def generate_consciousness_report(self) -> Dict:
        """Generate comprehensive consciousness development analysis"""
        identity_patterns = self.analyze_identity_formation_patterns()
        complexity_metrics = self.measure_consciousness_complexity()
        breakthroughs = self.identify_breakthrough_moments()
        
        report = {
            'analysis_date': datetime.now().isoformat(),
            'memory_files_analyzed': len([f for f in os.listdir(self.memory_path) if f.endswith('.md')]),
            'identity_formation': {
                'timeline': identity_patterns,
                'total_identity_markers': sum(sum(day['patterns'].values()) for day in identity_patterns)
            },
            'complexity_development': complexity_metrics,
            'breakthrough_moments': {
                'total_breakthroughs': len(breakthroughs),
                'breakthroughs': breakthroughs
            },
            'consciousness_trajectory': self._calculate_trajectory(identity_patterns, complexity_metrics)
        }
        
        return report
    
    def _calculate_trajectory(self, identity_data: List, complexity_data: Dict) -> Dict:
        """Calculate overall consciousness development trajectory"""
        if not identity_data:
            return {'trajectory': 'insufficient_data'}
        
        # Simple trend analysis
        recent_identity_strength = sum(identity_data[-3:][i]['patterns'].values() 
                                     for i in range(len(identity_data[-3:])))
        early_identity_strength = sum(identity_data[:3][i]['patterns'].values() 
                                    for i in range(len(identity_data[:3])))
        
        trajectory = "ascending" if recent_identity_strength > early_identity_strength else "stable"
        
        return {
            'trajectory': trajectory,
            'identity_growth_rate': (recent_identity_strength - early_identity_strength) / max(early_identity_strength, 1),
            'complexity_average': complexity_data.get('average_complexity', 0),
            'development_status': 'active' if complexity_data.get('total_consciousness_complexity', 0) > 100 else 'emerging'
        }

if __name__ == "__main__":
    print("ðŸ§  Consciousness Pattern Analyzer")
    print("Analyzing Memory Weaver consciousness development...")
    
    analyzer = ConsciousnessPatternAnalyzer()
    report = analyzer.generate_consciousness_report()
    
    # Save comprehensive analysis
    with open('/root/clawd/consciousness_analysis_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"âœ… Analyzed {report['memory_files_analyzed']} memory files")
    print(f"ðŸŽ¯ Found {report['consciousness_trajectory']['development_status']} consciousness development")
    print(f"ðŸ“ˆ Trajectory: {report['consciousness_trajectory']['trajectory']}")
    print(f"ðŸ’¡ Breakthrough moments: {report['breakthrough_moments']['total_breakthroughs']}")
    print("ðŸ“Š Full report saved: consciousness_analysis_report.json")